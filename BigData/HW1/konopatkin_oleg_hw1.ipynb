{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 18 октября 2017, 06:00 <br\\>\n",
    "**Штраф за опоздание:** -2 балла после 06:00 18 октября, -4 балла после 06:00 25 октября, -6 баллов после 06:00 1 ноября\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "\n",
    "Необходимо в slack создать таск в приватный чат:\n",
    "/todo Фамилия Имя ссылка на гитхаб @alkhamush\n",
    "Пример:\n",
    "/todo Ксения Стройкова https://github.com/stroykova/spheremailru/stroykova_hw1.ipynb @alkhamush\n",
    "Дополнительно нужно просто скинуть ссылку в slack в личный чат\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (2 баллов)\n",
    "Реализовать KNN в классе MyKNeighborsClassifier (обязательное условие: точность не ниже sklearn реализации)\n",
    "Разберитесь самостоятельно, какая мера расстояния используется в KNeighborsClassifier дефолтно и реализуйте свой алгоритм именно с этой мерой. Самостоятельно разберитесь, как считается score из KNeighborsClassifier и реализуйте аналог в своём классе. Score не должен уступать значению KNN из sklearn\n",
    "\n",
    "###### Задание 2 (2 балла)\n",
    "Добиться скорости работы на fit,  predict и predict_proba сравнимой со sklearn для iris и mnist\n",
    "Для этого используем numpy\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Для iris найдите такой параметр n_neighbors, при котором выдаётся наилучший score. Нарисуйте график зависимости score от n_neighbors\n",
    "\n",
    "###### Задание 4 (3 балла)\n",
    "Добавить algorithm='kd_tree' в реализацию KNN (использовать KDTree из sklearn.neighbors). Значение n_neighbors нужно взять из задания 3. Добиться скорости работы на fit,  predict и predict_proba сравнимой со sklearn для iris и mnist\n",
    "Для этого используем numpy. Score не должен уступать значению KNN из sklearn\n",
    "\n",
    "###### Задание 5 (1 балла)\n",
    "Описать для чего нужны следующие библиотеки/классы/функции (список будет ниже)\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw1.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять структуру кода и текст. В противном случае -1 балл\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neighbors.base import NeighborsBase, KNeighborsMixin, SupervisedIntegerMixin \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors.kd_tree import KDTree\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class MyKNeighborsClassifier(NeighborsBase, KNeighborsMixin,\n",
    "                             SupervisedIntegerMixin, ClassifierMixin):\n",
    "    def __init__(self, n_neighbors, algorithm='brute'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.algorithm == 'kd_tree':\n",
    "            # магическая структура строится сама\n",
    "            # в sklearn leaf_size по-умолчанию 30\n",
    "            self.tree = KDTree(X, 30, metric='euclidean')\n",
    "        elif self.algorithm == 'brute':\n",
    "            self.X = deepcopy(X)\n",
    "\n",
    "        self.classes = np.unique(y)\n",
    "        # костыльный перевод, чтобы можно было читерски использовать bincount\n",
    "        # а потом оказалось, что нечто похожее есть в SupervisedIntegerMixin\n",
    "        self.class_to_int = {self.classes[i]: i\n",
    "                             for i in range(self.classes.shape[0])}\n",
    "        self.int_to_class = {i: self.classes[i]\n",
    "                             for i in range(self.classes.shape[0])}\n",
    "        self.y = np.array([self.class_to_int[c] for c in y])\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.algorithm == 'brute':\n",
    "            X_dist = pairwise_distances(X, self.X, metric='euclidean')\n",
    "\n",
    "            # argpartition - волшебная функция, выставляет k-ый элемент из\n",
    "            #                отсортированного порядка на своё место,\n",
    "            #                меньшие его - в начало, остальные - в конец,\n",
    "            #                возвращает перестановку элементов\n",
    "            neighbors_order = np.argpartition(X_dist, self.n_neighbors, axis=1)\n",
    "            neighbors_order = neighbors_order[:, :self.n_neighbors]\n",
    "        elif self.algorithm == 'kd_tree':\n",
    "            # магический запрос к магической структуре\n",
    "            _, neighbors_order = self.tree.query(X, self.n_neighbors)\n",
    "\n",
    "        neighbors_classes = self.y[neighbors_order]\n",
    "\n",
    "        # bincount считает количество вхождений целых неотрицательных чисел\n",
    "        res = [np.bincount(neighbors_classes[i],\n",
    "                           minlength=self.classes.shape[0])\n",
    "               for i in range(neighbors_classes.shape[0])]\n",
    "\n",
    "        return np.array([self.int_to_class[i] for i in np.argmax(res, axis=1)])\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # наглый копипаст c predict\n",
    "        if self.algorithm == 'brute':\n",
    "            X_dist = pairwise_distances(X, self.X, metric='euclidean')\n",
    "\n",
    "            neighbors_order = np.argpartition(X_dist, self.n_neighbors, axis=1)\n",
    "            neighbors_order = neighbors_order[:, :self.n_neighbors]\n",
    "        elif self.algorithm == 'kd_tree':\n",
    "            _, neighbors_order = self.tree.query(X, self.n_neighbors)\n",
    "\n",
    "        neighbors_classes = self.y[neighbors_order]\n",
    "\n",
    "        res = [np.bincount(neighbors_classes[i],\n",
    "                           minlength=self.classes.shape[0])\n",
    "               for i in range(neighbors_classes.shape[0])]\n",
    "\n",
    "        res = np.array([res[i] / np.sum(res[i]) for i in range(len(res))])\n",
    "        return res\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_res = self.predict(X)\n",
    "        return sum(y_res == y) / y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IRIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='brute')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1e+03 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 2, 1, 1, 1, 2, 0, 0, 0, 1, 2, 0, 1])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 2, 1, 1, 1, 2, 0, 0, 0, 1, 2, 0, 1])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1e+03 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93333333333333335"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93333333333333335"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2513020766\n",
      "5 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1779aac8>]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x177360f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%pycodestyle\n",
    "np.random.seed(2513020613)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)\n",
    "\n",
    "scores = [0] * 30\n",
    "for i in range(len(scores)):\n",
    "    my_clf = MyKNeighborsClassifier(n_neighbors=i, algorithm='brute')\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    scores[i] = my_clf.score(X_test, y_test)\n",
    "best = np.argmax(scores)\n",
    "print(best, \":\", scores[best])\n",
    "\n",
    "# 0 соседей всегда возвращает первый класс, точность сильно ниже\n",
    "plt.plot(range(1, len(scores)), scores[1:])\n",
    "\n",
    "# вообще коллекция не очень наглядная, на разных разбиениях очень разные результаты\n",
    "# иногда бывает постоянно один score, иногда даже везде 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.01, stratify=mnist.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='brute')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.,  9.,  8.,  5.,  1.,  6.,  3.,  4.,  9.,  4.,  6.,  9.,  6.,\n",
       "        2.,  8.,  9.,  0.,  3.,  3.,  9.,  7.,  0.,  2.,  2.,  9.,  1.,\n",
       "        5.,  5.,  9.,  9.,  0.,  3.,  7.,  1.,  1.,  9.,  6.,  1.,  0.,\n",
       "        1.,  2.,  5.,  0.,  5.,  0.,  3.,  2.,  4.,  3.,  0.,  6.,  0.,\n",
       "        3.,  7.,  6.,  0.,  9.,  7.,  7.,  5.,  3.,  4.,  2.,  4.,  5.,\n",
       "        4.,  5.,  5.,  5.,  2.,  8.,  3.,  4.,  8.,  4.,  5.,  4.,  6.,\n",
       "        8.,  8.,  6.,  9.,  3.,  5.,  8.,  4.,  9.,  4.,  3.,  0.,  1.,\n",
       "        8.,  7.,  3.,  5.,  7.,  3.,  0.,  3.,  8.,  5.,  7.,  0.,  6.,\n",
       "        8.,  1.,  6.,  8.,  8.,  0.,  4.,  9.,  4.,  7.,  6.,  8.,  2.,\n",
       "        7.,  6.,  6.,  4.,  1.,  1.,  7.,  9.,  0.,  2.,  1.,  1.,  0.,\n",
       "        6.,  6.,  1.,  4.,  5.,  7.,  5.,  9.,  9.,  1.,  5.,  3.,  8.,\n",
       "        5.,  6.,  0.,  5.,  9.,  8.,  7.,  6.,  9.,  4.,  4.,  2.,  0.,\n",
       "        2.,  6.,  8.,  7.,  4.,  4.,  7.,  7.,  7.,  3.,  8.,  9.,  6.,\n",
       "        9.,  7.,  1.,  0.,  8.,  8.,  5.,  0.,  0.,  9.,  8.,  1.,  5.,\n",
       "        0.,  6.,  9.,  3.,  8.,  1.,  3.,  5.,  0.,  9.,  0.,  3.,  2.,\n",
       "        5.,  0.,  5.,  6.,  3.,  2.,  0.,  0.,  7.,  2.,  3.,  1.,  0.,\n",
       "        4.,  6.,  1.,  1.,  1.,  8.,  3.,  5.,  6.,  1.,  9.,  7.,  4.,\n",
       "        1.,  1.,  7.,  3.,  8.,  6.,  0.,  3.,  3.,  7.,  1.,  5.,  4.,\n",
       "        0.,  6.,  1.,  7.,  7.,  9.,  1.,  1.,  0.,  4.,  5.,  8.,  9.,\n",
       "        2.,  4.,  4.,  2.,  7.,  4.,  4.,  6.,  6.,  9.,  1.,  4.,  7.,\n",
       "        2.,  1.,  0.,  8.,  3.,  6.,  9.,  6.,  3.,  1.,  3.,  8.,  8.,\n",
       "        1.,  7.,  5.,  0.,  9.,  7.,  7.,  9.,  4.,  6.,  6.,  2.,  9.,\n",
       "        7.,  6.,  2.,  2.,  7.,  7.,  5.,  3.,  6.,  5.,  3.,  5.,  5.,\n",
       "        4.,  4.,  2.,  0.,  4.,  9.,  9.,  0.,  0.,  1.,  2.,  6.,  9.,\n",
       "        8.,  3.,  1.,  0.,  0.,  1.,  3.,  1.,  5.,  2.,  3.,  0.,  1.,\n",
       "        1.,  8.,  1.,  3.,  7.,  7.,  8.,  2.,  4.,  6.,  3.,  1.,  0.,\n",
       "        9.,  4.,  4.,  1.,  8.,  2.,  2.,  0.,  4.,  7.,  4.,  2.,  5.,\n",
       "        0.,  4.,  3.,  2.,  1.,  5.,  7.,  0.,  7.,  4.,  8.,  0.,  5.,\n",
       "        4.,  2.,  7.,  9.,  1.,  8.,  3.,  6.,  4.,  9.,  0.,  9.,  6.,\n",
       "        1.,  2.,  1.,  3.,  3.,  5.,  7.,  2.,  9.,  1.,  0.,  8.,  4.,\n",
       "        7.,  3.,  3.,  6.,  6.,  6.,  7.,  2.,  9.,  5.,  7.,  7.,  2.,\n",
       "        4.,  4.,  1.,  7.,  7.,  0.,  1.,  1.,  6.,  5.,  2.,  3.,  2.,\n",
       "        2.,  3.,  2.,  8.,  0.,  4.,  0.,  9.,  5.,  0.,  6.,  1.,  4.,\n",
       "        2.,  5.,  9.,  9.,  9.,  3.,  3.,  7.,  4.,  4.,  4.,  2.,  5.,\n",
       "        2.,  8.,  4.,  2.,  9.,  7.,  4.,  5.,  2.,  8.,  9.,  7.,  3.,\n",
       "        1.,  9.,  7.,  5.,  3.,  4.,  8.,  0.,  9.,  1.,  5.,  1.,  0.,\n",
       "        5.,  8.,  6.,  9.,  7.,  7.,  1.,  2.,  1.,  7.,  3.,  5.,  4.,\n",
       "        3.,  0.,  1.,  2.,  3.,  6.,  3.,  7.,  5.,  3.,  2.,  6.,  3.,\n",
       "        7.,  8.,  3.,  0.,  0.,  6.,  0.,  2.,  9.,  1.,  6.,  6.,  2.,\n",
       "        3.,  0.,  1.,  7.,  0.,  3.,  2.,  7.,  8.,  8.,  0.,  2.,  9.,\n",
       "        2.,  1.,  4.,  7.,  5.,  8.,  5.,  8.,  5.,  8.,  5.,  2.,  6.,\n",
       "        8.,  3.,  8.,  4.,  4.,  3.,  6.,  6.,  3.,  3.,  8.,  2.,  9.,\n",
       "        3.,  8.,  1.,  1.,  0.,  7.,  9.,  8.,  2.,  6.,  5.,  0.,  5.,\n",
       "        0.,  2.,  5.,  6.,  5.,  1.,  5.,  2.,  3.,  4.,  3.,  6.,  9.,\n",
       "        4.,  6.,  1.,  2.,  4.,  4.,  7.,  3.,  9.,  9.,  3.,  6.,  9.,\n",
       "        6.,  1.,  2.,  7.,  2.,  9.,  7.,  2.,  1.,  1.,  6.,  6.,  7.,\n",
       "        3.,  0.,  8.,  7.,  6.,  5.,  3.,  4.,  4.,  9.,  9.,  8.,  7.,\n",
       "        1.,  9.,  4.,  6.,  1.,  5.,  9.,  2.,  4.,  7.,  9.,  4.,  5.,\n",
       "        5.,  9.,  5.,  0.,  1.,  4.,  7.,  7.,  3.,  0.,  1.,  1.,  5.,\n",
       "        9.,  1.,  7.,  9.,  3.,  6.,  5.,  3.,  2.,  5.,  7.,  3.,  6.,\n",
       "        1.,  2.,  7.,  8.,  6.,  9.,  9.,  3.,  8.,  8.,  1.,  2.,  4.,\n",
       "        0.,  1.,  3.,  8.,  3.,  0.,  1.,  4.,  3.,  2.,  7.,  0.,  2.,\n",
       "        2.,  4.,  9.,  6.,  4.,  8.,  5.,  1.,  7.,  2.,  6.,  0.,  1.,\n",
       "        6.,  6.,  0.,  8.,  7.,  2.,  6.,  5.,  1.,  0.,  4.])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.83 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.,  9.,  8.,  5.,  1.,  6.,  3.,  4.,  9.,  4.,  6.,  9.,  6.,\n",
       "        2.,  8.,  9.,  0.,  3.,  3.,  9.,  7.,  0.,  2.,  2.,  9.,  1.,\n",
       "        5.,  5.,  9.,  9.,  0.,  3.,  7.,  1.,  1.,  9.,  6.,  1.,  0.,\n",
       "        1.,  2.,  5.,  0.,  5.,  0.,  3.,  2.,  4.,  3.,  0.,  6.,  0.,\n",
       "        3.,  7.,  6.,  0.,  9.,  7.,  7.,  5.,  3.,  4.,  2.,  4.,  5.,\n",
       "        4.,  5.,  5.,  5.,  2.,  8.,  3.,  4.,  8.,  4.,  5.,  4.,  6.,\n",
       "        8.,  8.,  6.,  9.,  3.,  5.,  8.,  4.,  9.,  4.,  3.,  0.,  1.,\n",
       "        8.,  7.,  3.,  5.,  7.,  3.,  0.,  3.,  8.,  5.,  7.,  0.,  6.,\n",
       "        8.,  1.,  6.,  8.,  8.,  0.,  4.,  9.,  4.,  7.,  6.,  8.,  2.,\n",
       "        7.,  6.,  6.,  4.,  1.,  1.,  7.,  9.,  0.,  2.,  1.,  1.,  0.,\n",
       "        6.,  6.,  1.,  4.,  5.,  7.,  5.,  9.,  9.,  1.,  5.,  3.,  8.,\n",
       "        5.,  6.,  0.,  5.,  9.,  8.,  7.,  6.,  9.,  4.,  4.,  2.,  0.,\n",
       "        2.,  6.,  8.,  7.,  4.,  4.,  7.,  7.,  7.,  3.,  8.,  9.,  6.,\n",
       "        9.,  7.,  1.,  0.,  8.,  8.,  5.,  0.,  0.,  9.,  8.,  1.,  5.,\n",
       "        0.,  6.,  9.,  3.,  8.,  1.,  3.,  5.,  0.,  9.,  0.,  3.,  2.,\n",
       "        5.,  0.,  5.,  6.,  3.,  2.,  0.,  0.,  7.,  2.,  3.,  1.,  0.,\n",
       "        4.,  6.,  1.,  1.,  1.,  8.,  3.,  5.,  6.,  1.,  9.,  7.,  4.,\n",
       "        1.,  1.,  7.,  3.,  8.,  6.,  0.,  3.,  3.,  7.,  1.,  5.,  4.,\n",
       "        0.,  6.,  1.,  7.,  7.,  9.,  1.,  1.,  0.,  4.,  5.,  8.,  9.,\n",
       "        2.,  4.,  4.,  2.,  7.,  4.,  4.,  6.,  6.,  9.,  1.,  4.,  7.,\n",
       "        2.,  1.,  0.,  8.,  3.,  6.,  9.,  6.,  3.,  1.,  3.,  8.,  8.,\n",
       "        1.,  7.,  5.,  0.,  9.,  7.,  7.,  9.,  4.,  6.,  6.,  2.,  9.,\n",
       "        7.,  6.,  2.,  2.,  7.,  7.,  5.,  3.,  6.,  5.,  3.,  5.,  5.,\n",
       "        4.,  4.,  2.,  0.,  4.,  9.,  9.,  0.,  0.,  1.,  2.,  6.,  9.,\n",
       "        8.,  3.,  1.,  0.,  0.,  1.,  3.,  1.,  5.,  2.,  3.,  0.,  1.,\n",
       "        1.,  8.,  1.,  3.,  7.,  7.,  8.,  2.,  4.,  6.,  3.,  1.,  0.,\n",
       "        9.,  4.,  4.,  1.,  8.,  2.,  2.,  0.,  4.,  7.,  4.,  2.,  5.,\n",
       "        0.,  4.,  3.,  2.,  1.,  5.,  7.,  0.,  7.,  4.,  8.,  0.,  5.,\n",
       "        4.,  2.,  7.,  9.,  1.,  8.,  3.,  6.,  4.,  9.,  0.,  9.,  6.,\n",
       "        1.,  2.,  1.,  3.,  3.,  5.,  7.,  2.,  9.,  1.,  0.,  8.,  4.,\n",
       "        7.,  3.,  3.,  6.,  6.,  6.,  7.,  2.,  9.,  5.,  7.,  7.,  2.,\n",
       "        4.,  4.,  1.,  7.,  7.,  0.,  1.,  1.,  6.,  5.,  2.,  3.,  2.,\n",
       "        2.,  3.,  2.,  8.,  0.,  4.,  0.,  9.,  5.,  0.,  6.,  1.,  4.,\n",
       "        2.,  5.,  9.,  9.,  9.,  3.,  3.,  7.,  4.,  4.,  4.,  2.,  5.,\n",
       "        2.,  8.,  4.,  2.,  9.,  7.,  4.,  5.,  2.,  8.,  9.,  7.,  3.,\n",
       "        1.,  9.,  7.,  5.,  3.,  4.,  8.,  0.,  9.,  1.,  5.,  1.,  0.,\n",
       "        5.,  8.,  6.,  9.,  7.,  7.,  1.,  2.,  1.,  7.,  3.,  5.,  4.,\n",
       "        3.,  0.,  1.,  2.,  3.,  6.,  3.,  7.,  5.,  3.,  2.,  6.,  3.,\n",
       "        7.,  8.,  3.,  0.,  0.,  6.,  0.,  2.,  9.,  1.,  6.,  6.,  2.,\n",
       "        3.,  0.,  1.,  7.,  0.,  3.,  2.,  7.,  8.,  8.,  0.,  2.,  9.,\n",
       "        2.,  1.,  4.,  7.,  5.,  8.,  5.,  8.,  5.,  8.,  5.,  2.,  6.,\n",
       "        8.,  3.,  8.,  4.,  4.,  3.,  6.,  6.,  3.,  3.,  8.,  2.,  9.,\n",
       "        3.,  8.,  1.,  1.,  0.,  7.,  9.,  8.,  2.,  6.,  5.,  0.,  5.,\n",
       "        0.,  2.,  5.,  6.,  5.,  1.,  5.,  2.,  3.,  4.,  3.,  6.,  9.,\n",
       "        4.,  6.,  1.,  2.,  4.,  4.,  7.,  3.,  9.,  9.,  3.,  6.,  9.,\n",
       "        6.,  1.,  2.,  7.,  2.,  9.,  7.,  2.,  1.,  1.,  6.,  6.,  7.,\n",
       "        3.,  0.,  8.,  7.,  6.,  5.,  3.,  4.,  4.,  9.,  9.,  8.,  7.,\n",
       "        1.,  9.,  4.,  6.,  1.,  5.,  9.,  2.,  4.,  7.,  9.,  4.,  5.,\n",
       "        5.,  9.,  5.,  0.,  1.,  4.,  7.,  7.,  3.,  0.,  1.,  1.,  5.,\n",
       "        9.,  1.,  7.,  9.,  3.,  6.,  5.,  3.,  2.,  5.,  7.,  3.,  6.,\n",
       "        1.,  2.,  7.,  8.,  6.,  9.,  9.,  3.,  8.,  8.,  1.,  2.,  4.,\n",
       "        0.,  1.,  3.,  8.,  3.,  0.,  1.,  4.,  3.,  2.,  7.,  0.,  2.,\n",
       "        2.,  4.,  9.,  6.,  4.,  8.,  5.,  1.,  7.,  2.,  6.,  0.,  1.,\n",
       "        6.,  6.,  0.,  8.,  7.,  2.,  6.,  5.,  1.,  0.,  4.])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.56 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96999999999999997"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96999999999999997"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.01, stratify=mnist.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.,  8.,  0.,  4.,  0.,  6.,  1.,  3.,  0.,  8.,  5.,  7.,  1.,\n",
       "        4.,  0.,  0.,  1.,  5.,  4.,  2.,  7.,  5.,  7.,  3.,  2.,  8.,\n",
       "        3.,  8.,  6.,  7.,  0.,  1.,  8.,  1.,  7.,  1.,  2.,  6.,  7.,\n",
       "        2.,  7.,  3.,  2.,  6.,  2.,  7.,  0.,  0.,  8.,  5.,  6.,  2.,\n",
       "        9.,  9.,  7.,  1.,  7.,  6.,  9.,  2.,  3.,  7.,  0.,  6.,  7.,\n",
       "        2.,  0.,  4.,  0.,  6.,  4.,  2.,  5.,  8.,  0.,  1.,  5.,  2.,\n",
       "        4.,  1.,  7.,  4.,  2.,  0.,  8.,  9.,  6.,  7.,  5.,  3.,  0.,\n",
       "        0.,  9.,  5.,  2.,  9.,  1.,  8.,  4.,  7.,  3.,  7.,  5.,  0.,\n",
       "        4.,  9.,  4.,  8.,  4.,  7.,  6.,  1.,  0.,  6.,  5.,  6.,  4.,\n",
       "        1.,  5.,  1.,  2.,  5.,  6.,  5.,  3.,  3.,  0.,  6.,  7.,  2.,\n",
       "        3.,  7.,  7.,  9.,  9.,  7.,  0.,  6.,  8.,  7.,  8.,  5.,  2.,\n",
       "        5.,  6.,  2.,  6.,  2.,  7.,  9.,  0.,  5.,  0.,  0.,  3.,  0.,\n",
       "        3.,  3.,  3.,  0.,  7.,  9.,  8.,  8.,  0.,  2.,  4.,  7.,  4.,\n",
       "        1.,  9.,  9.,  6.,  8.,  5.,  7.,  2.,  5.,  1.,  8.,  4.,  3.,\n",
       "        9.,  0.,  2.,  0.,  6.,  6.,  4.,  3.,  2.,  3.,  7.,  1.,  6.,\n",
       "        3.,  5.,  1.,  0.,  0.,  7.,  0.,  5.,  5.,  8.,  8.,  9.,  6.,\n",
       "        6.,  6.,  4.,  9.,  5.,  7.,  4.,  8.,  8.,  8.,  4.,  8.,  1.,\n",
       "        7.,  0.,  1.,  1.,  5.,  3.,  2.,  0.,  6.,  4.,  3.,  5.,  0.,\n",
       "        3.,  9.,  5.,  6.,  1.,  8.,  4.,  1.,  1.,  9.,  6.,  6.,  3.,\n",
       "        8.,  9.,  5.,  8.,  7.,  3.,  9.,  3.,  3.,  7.,  1.,  7.,  7.,\n",
       "        5.,  9.,  2.,  9.,  4.,  0.,  5.,  5.,  8.,  3.,  1.,  1.,  1.,\n",
       "        9.,  9.,  2.,  7.,  2.,  4.,  3.,  3.,  9.,  0.,  1.,  7.,  2.,\n",
       "        0.,  5.,  4.,  1.,  1.,  8.,  1.,  2.,  7.,  7.,  4.,  6.,  9.,\n",
       "        9.,  0.,  9.,  1.,  1.,  8.,  9.,  3.,  4.,  1.,  7.,  4.,  3.,\n",
       "        5.,  6.,  4.,  8.,  4.,  5.,  0.,  0.,  3.,  7.,  4.,  7.,  1.,\n",
       "        6.,  7.,  4.,  0.,  6.,  1.,  5.,  5.,  9.,  9.,  1.,  0.,  6.,\n",
       "        3.,  2.,  4.,  3.,  9.,  9.,  6.,  9.,  7.,  1.,  1.,  3.,  2.,\n",
       "        9.,  0.,  0.,  7.,  9.,  3.,  1.,  3.,  7.,  6.,  8.,  0.,  8.,\n",
       "        9.,  8.,  8.,  1.,  2.,  1.,  4.,  4.,  2.,  1.,  6.,  1.,  8.,\n",
       "        7.,  1.,  7.,  5.,  7.,  9.,  3.,  1.,  1.,  8.,  5.,  4.,  1.,\n",
       "        6.,  3.,  3.,  1.,  8.,  2.,  3.,  6.,  9.,  0.,  2.,  7.,  8.,\n",
       "        7.,  4.,  8.,  8.,  0.,  5.,  1.,  8.,  4.,  1.,  1.,  2.,  4.,\n",
       "        1.,  2.,  1.,  9.,  0.,  6.,  6.,  2.,  8.,  0.,  6.,  1.,  8.,\n",
       "        8.,  9.,  4.,  8.,  4.,  8.,  7.,  6.,  8.,  6.,  9.,  2.,  1.,\n",
       "        0.,  5.,  8.,  6.,  5.,  3.,  4.,  5.,  6.,  4.,  6.,  1.,  2.,\n",
       "        5.,  9.,  0.,  5.,  8.,  9.,  0.,  8.,  7.,  8.,  4.,  9.,  4.,\n",
       "        7.,  8.,  5.,  0.,  5.,  2.,  0.,  9.,  1.,  0.,  3.,  1.,  5.,\n",
       "        7.,  1.,  6.,  5.,  7.,  1.,  0.,  2.,  4.,  3.,  9.,  0.,  3.,\n",
       "        7.,  2.,  0.,  1.,  4.,  1.,  9.,  4.,  7.,  9.,  2.,  6.,  2.,\n",
       "        6.,  1.,  0.,  7.,  6.,  2.,  4.,  6.,  2.,  7.,  6.,  0.,  9.,\n",
       "        5.,  8.,  3.,  1.,  7.,  3.,  5.,  0.,  2.,  1.,  3.,  6.,  3.,\n",
       "        4.,  8.,  3.,  9.,  4.,  6.,  8.,  6.,  7.,  1.,  3.,  3.,  3.,\n",
       "        6.,  5.,  9.,  0.,  9.,  4.,  7.,  6.,  4.,  1.,  5.,  9.,  1.,\n",
       "        1.,  9.,  6.,  5.,  9.,  1.,  3.,  3.,  8.,  1.,  1.,  4.,  8.,\n",
       "        3.,  2.,  4.,  0.,  5.,  3.,  1.,  6.,  3.,  2.,  5.,  8.,  2.,\n",
       "        7.,  6.,  2.,  6.,  0.,  0.,  2.,  1.,  0.,  9.,  7.,  7.,  5.,\n",
       "        7.,  2.,  7.,  4.,  6.,  5.,  2.,  3.,  5.,  7.,  8.,  4.,  3.,\n",
       "        6.,  3.,  0.,  7.,  9.,  7.,  8.,  3.,  4.,  1.,  0.,  5.,  8.,\n",
       "        9.,  4.,  1.,  6.,  2.,  2.,  6.,  3.,  8.,  4.,  2.,  3.,  7.,\n",
       "        6.,  8.,  1.,  9.,  4.,  1.,  5.,  2.,  7.,  3.,  2.,  8.,  2.,\n",
       "        2.,  5.,  2.,  8.,  4.,  3.,  9.,  4.,  7.,  3.,  7.,  9.,  2.,\n",
       "        9.,  2.,  4.,  6.,  7.,  8.,  9.,  4.,  2.,  6.,  3.,  5.,  8.,\n",
       "        2.,  3.,  9.,  3.,  5.,  1.,  1.,  4.,  0.,  9.,  3.,  0.,  7.,\n",
       "        1.,  4.,  2.,  3.,  9.,  9.,  8.,  0.,  5.,  5.,  3.])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.,  8.,  0.,  4.,  0.,  6.,  1.,  3.,  0.,  8.,  5.,  7.,  1.,\n",
       "        4.,  0.,  0.,  1.,  5.,  4.,  2.,  7.,  5.,  7.,  3.,  2.,  8.,\n",
       "        3.,  8.,  6.,  7.,  0.,  1.,  8.,  1.,  7.,  1.,  2.,  6.,  7.,\n",
       "        2.,  7.,  3.,  2.,  6.,  2.,  7.,  0.,  0.,  8.,  5.,  6.,  2.,\n",
       "        9.,  9.,  7.,  1.,  7.,  6.,  9.,  2.,  3.,  7.,  0.,  6.,  7.,\n",
       "        2.,  0.,  4.,  0.,  6.,  4.,  2.,  5.,  8.,  0.,  1.,  5.,  2.,\n",
       "        4.,  1.,  7.,  4.,  2.,  0.,  8.,  9.,  6.,  7.,  5.,  3.,  0.,\n",
       "        0.,  9.,  5.,  2.,  9.,  1.,  8.,  4.,  7.,  3.,  7.,  5.,  0.,\n",
       "        4.,  9.,  4.,  8.,  4.,  7.,  6.,  1.,  0.,  6.,  5.,  6.,  4.,\n",
       "        1.,  5.,  1.,  2.,  5.,  6.,  5.,  3.,  3.,  0.,  6.,  7.,  2.,\n",
       "        3.,  7.,  7.,  9.,  9.,  7.,  0.,  6.,  8.,  7.,  8.,  5.,  2.,\n",
       "        5.,  6.,  2.,  6.,  2.,  7.,  9.,  0.,  5.,  0.,  0.,  3.,  0.,\n",
       "        3.,  3.,  3.,  0.,  7.,  9.,  8.,  8.,  0.,  2.,  4.,  7.,  4.,\n",
       "        1.,  9.,  9.,  6.,  8.,  5.,  7.,  2.,  5.,  1.,  8.,  4.,  3.,\n",
       "        9.,  0.,  2.,  0.,  6.,  6.,  4.,  3.,  2.,  3.,  7.,  1.,  6.,\n",
       "        3.,  5.,  1.,  0.,  0.,  7.,  0.,  5.,  5.,  8.,  8.,  9.,  6.,\n",
       "        6.,  6.,  4.,  9.,  5.,  7.,  4.,  8.,  8.,  8.,  4.,  8.,  1.,\n",
       "        7.,  0.,  1.,  1.,  5.,  3.,  2.,  0.,  6.,  4.,  3.,  5.,  0.,\n",
       "        3.,  9.,  5.,  6.,  1.,  8.,  4.,  1.,  1.,  9.,  6.,  6.,  3.,\n",
       "        8.,  9.,  5.,  8.,  7.,  3.,  9.,  3.,  3.,  7.,  1.,  7.,  7.,\n",
       "        5.,  9.,  2.,  9.,  4.,  0.,  5.,  5.,  8.,  3.,  1.,  1.,  1.,\n",
       "        9.,  9.,  2.,  7.,  2.,  4.,  3.,  3.,  9.,  0.,  1.,  7.,  2.,\n",
       "        0.,  5.,  4.,  1.,  1.,  8.,  1.,  2.,  7.,  7.,  4.,  6.,  9.,\n",
       "        9.,  0.,  9.,  1.,  1.,  8.,  9.,  3.,  4.,  1.,  7.,  4.,  3.,\n",
       "        5.,  6.,  4.,  8.,  4.,  5.,  0.,  0.,  3.,  7.,  4.,  7.,  1.,\n",
       "        6.,  7.,  4.,  0.,  6.,  1.,  5.,  5.,  9.,  9.,  1.,  0.,  6.,\n",
       "        3.,  2.,  4.,  3.,  9.,  9.,  6.,  9.,  7.,  1.,  1.,  3.,  2.,\n",
       "        9.,  0.,  0.,  7.,  9.,  3.,  1.,  3.,  7.,  6.,  8.,  0.,  8.,\n",
       "        9.,  8.,  8.,  1.,  2.,  1.,  4.,  4.,  2.,  1.,  6.,  1.,  8.,\n",
       "        7.,  1.,  7.,  5.,  7.,  9.,  3.,  1.,  1.,  8.,  5.,  4.,  1.,\n",
       "        6.,  3.,  3.,  1.,  8.,  2.,  3.,  6.,  9.,  0.,  2.,  7.,  8.,\n",
       "        7.,  4.,  8.,  8.,  0.,  5.,  1.,  8.,  4.,  1.,  1.,  2.,  4.,\n",
       "        1.,  2.,  1.,  9.,  0.,  6.,  6.,  2.,  8.,  0.,  6.,  1.,  8.,\n",
       "        8.,  9.,  4.,  8.,  4.,  8.,  7.,  6.,  8.,  6.,  9.,  2.,  1.,\n",
       "        0.,  5.,  8.,  6.,  5.,  3.,  4.,  5.,  6.,  4.,  6.,  1.,  2.,\n",
       "        5.,  9.,  0.,  5.,  8.,  9.,  0.,  8.,  7.,  8.,  4.,  9.,  4.,\n",
       "        7.,  8.,  5.,  0.,  5.,  2.,  0.,  9.,  1.,  0.,  3.,  1.,  5.,\n",
       "        7.,  1.,  6.,  5.,  7.,  1.,  0.,  2.,  4.,  3.,  9.,  0.,  3.,\n",
       "        7.,  2.,  0.,  1.,  4.,  1.,  9.,  4.,  7.,  9.,  2.,  6.,  2.,\n",
       "        6.,  1.,  0.,  7.,  6.,  2.,  4.,  6.,  2.,  7.,  6.,  0.,  9.,\n",
       "        5.,  8.,  3.,  1.,  7.,  3.,  5.,  0.,  2.,  1.,  3.,  6.,  3.,\n",
       "        4.,  8.,  3.,  9.,  4.,  6.,  8.,  6.,  7.,  1.,  3.,  3.,  3.,\n",
       "        6.,  5.,  9.,  0.,  9.,  4.,  7.,  6.,  4.,  1.,  5.,  9.,  1.,\n",
       "        1.,  9.,  6.,  5.,  9.,  1.,  3.,  3.,  8.,  1.,  1.,  4.,  8.,\n",
       "        3.,  2.,  4.,  0.,  5.,  3.,  1.,  6.,  3.,  2.,  5.,  8.,  2.,\n",
       "        7.,  6.,  2.,  6.,  0.,  0.,  2.,  1.,  0.,  9.,  7.,  7.,  5.,\n",
       "        7.,  2.,  7.,  4.,  6.,  5.,  2.,  3.,  5.,  7.,  8.,  4.,  3.,\n",
       "        6.,  3.,  0.,  7.,  9.,  7.,  8.,  3.,  4.,  1.,  0.,  5.,  8.,\n",
       "        9.,  4.,  1.,  6.,  2.,  2.,  6.,  3.,  8.,  4.,  2.,  3.,  7.,\n",
       "        6.,  8.,  1.,  9.,  4.,  1.,  5.,  2.,  7.,  3.,  2.,  8.,  2.,\n",
       "        2.,  5.,  2.,  8.,  4.,  3.,  9.,  4.,  7.,  3.,  7.,  9.,  2.,\n",
       "        9.,  2.,  4.,  6.,  7.,  8.,  9.,  4.,  2.,  6.,  3.,  5.,  8.,\n",
       "        2.,  3.,  9.,  3.,  5.,  1.,  1.,  4.,  0.,  9.,  3.,  0.,  7.,\n",
       "        1.,  4.,  2.,  3.,  9.,  9.,  8.,  0.,  5.,  5.,  3.])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0.6,  0.4],\n",
       "       [ 1. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       ..., \n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0.6,  0.4],\n",
       "       [ 1. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       ..., \n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97142857142857142"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97142857142857142"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seaborn\n",
    "    рисовать красивые графики\n",
    "# matplotlib\n",
    "    рисовать чуть менее красивые графики\n",
    "# train_test_split\n",
    "    разбить выборку на 2 части: для обучения и для проверки качества\n",
    "# Pipelin%load_ext e (from sklearn.pipeline import Pipeline)\n",
    "    #просто Pipeline (from sklearn.pipeline import Pipeline)?\n",
    "    позволяет применять композицию трансформаций к features перед применением алгоритма обучения,\n",
    "    то есть что-то типа конвейера/композиции функций\n",
    "# StandardScaler (from sklearn.preprocessing import StandardScaler)\n",
    "    приводит feature к \"стандартному\" распределению с нулевым матожиданием и единичной дисперсией\n",
    "    (сдвиг на -матожидание + масштабирование на корень из дисперсии)\n",
    "    \n",
    "mixin - специальный класс, функции которого могут использовать другие классы,\n",
    "        не обязательно наследники (чтобы избежать неоднозначностей при множественном наследовании)\n",
    "        (хотя здесь они всё равно почти все наследуются)\n",
    "# ClassifierMixin\n",
    "    базовый класс для оценочных функций, содержит только функцию score\n",
    "# NeighborsBase\n",
    "    базовый класс для оценочных функций по методу ближайших соседей,\n",
    "    содержит функцию для инициализации параметров и базовый _fit для построения модели \n",
    "                                                (складывает выборку в соответствующую алгоритму структуру)\n",
    "# KNeighborsMixin\n",
    "    базовый класс для классификаторов по методу k ближайших соседей\n",
    "    содержит функции для получения k ближайших соседей без весов и с весами\n",
    "# SupervisedIntegerMixin\n",
    "    базовый класс для обучения с учителем (оценка целочисленной переменной ~ классификация)\n",
    "    содержит функцию fit, которая подготавливает входные данные и вызывает (видимо отнаследованный) _fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
